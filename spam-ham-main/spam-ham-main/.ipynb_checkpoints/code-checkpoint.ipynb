{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9062aa44-2830-49dc-bf98-adbe8401f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "df = pd.read_csv('spamhamdata.csv',sep='\\t',names=[\"label\",\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebcbe10a-1dba-4bc2-99bf-5b77baf46a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point, crazy.. available only ...\n",
       "1                           ok lar... joking wif u oni...\n",
       "2       free entry in 2 a wkly comp to win fa cup fina...\n",
       "3       u dun say so early hor... u c already then say...\n",
       "4       nah i don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    this is the 2nd time we have tried 2 contact u...\n",
       "5568                 will Ã¼ b going to esplanade fr home?\n",
       "5569    pity, * was in mood for that. so...any other s...\n",
       "5570    the guy did some bitching but i acted like i'd...\n",
       "5571                           rofl. its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"label\"] = df['label'].replace({'ham':0,'spam':1})\n",
    "\n",
    "otput=df[\"label\"]\n",
    "sent=df[\"message\"].str.lower()\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8608f9e-3093-4848-8478-00f2f1729abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ddba414-fe35-467f-88b0-82b5362e2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "# st=PorterStemmer()\n",
    "st=WordNetLemmatizer()\n",
    "for i in range(len(sent)):\n",
    "    r=re.sub('[^A-Za-z]',' ',sent[i])\n",
    "    r=re.sub('\\s+',' ',r)\n",
    "    words=r.split()\n",
    "    #r=[st.stem(word) for word in words if not word in set(stopwords.words('english'))]\n",
    "    r=[st.lemmatize(word) for word in words if not word in set(stopwords.words('english'))]\n",
    "    r=' '.join(r)\n",
    "    corpus.append(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39b83e95-dcaa-4664-b1e8-475b0451f5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "obj = CountVectorizer()\n",
    "model = obj.fit_transform(corpus).toarray()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a343c15-cbb4-47a1-b24b-4bec5cdc16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=model \n",
    "Y=otput\n",
    "x_train,x_test , y_train , y_test = train_test_split(X,Y,test_size=0.2 , random_state= 0); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d847ce57-f34b-4939-9a23-f729cf74cf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf= MultinomialNB().fit(x_train,y_train)\n",
    "y_pred= clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0bad0e67-d46e-4904-af7d-111cfa60bebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802690582959641"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy= accuracy_score(y_pred,y_test); \n",
    "accuracy\n",
    "#0.979372197309417 stemming and naive bayes\n",
    "#0.9802690582959641 stemming and randomforest\n",
    "#0.9838565022421525 stemming and logistics Regression\n",
    "#0.9847533632286996 lemma and logistics Regression\n",
    "#0.9802690582959641 lemma and randomforest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78290b22-2c43-45a8-94e4-a4ae332bb2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
